# VSCode Ollama Extension

<p align="center">
  <img src="resources/logo.png" alt="VSCode Ollama Logo" width="128"/>
</p>

<p align="center">
  <a href="https://marketplace.visualstudio.com/items?itemName=vscode-ollama">
    <img src="https://img.shields.io/visual-studio-marketplace/v/vscode-ollama.svg?color=blue&label=VS%20Code%20Marketplace&logo=visual-studio-code" alt="Visual Studio Marketplace Version">
  </a>
  <a href="https://marketplace.visualstudio.com/items?itemName=vscode-ollama">
    <img src="https://img.shields.io/visual-studio-marketplace/d/vscode-ollama.svg?color=blue&label=Downloads&logo=visual-studio-code" alt="Visual Studio Marketplace Downloads">
  </a>
  <a href="https://github.com/warm3snow/vscode-ollama/blob/main/LICENSE">
    <img src="https://img.shields.io/github/license/warm3snow/vscode-ollama.svg?color=blue&label=License&logo=github" alt="License">
  </a>
</p>

VSCode Ollama æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ Visual Studio Code æ‰©å±•ï¼Œå®ƒå°† Ollama çš„æœ¬åœ° LLM èƒ½åŠ›æ— ç¼é›†æˆåˆ°æ‚¨çš„å¼€å‘ç¯å¢ƒä¸­ã€‚

## âœ¨ ç‰¹æ€§

- ğŸ¤– **æœ¬åœ° LLM æ”¯æŒ**
  - åŸºäº Ollama çš„æœ¬åœ°æ¨¡å‹è¿è¡Œ
  - æ”¯æŒå¤šç§æ¨¡å‹åˆ‡æ¢
  - ä½å»¶è¿Ÿå“åº”

- ğŸ” **è”ç½‘æœç´¢**
  - å®æ—¶ç½‘ç»œä¿¡æ¯é›†æˆ
  - æ™ºèƒ½æœç´¢ç»“æœæ•´åˆ
  - å‡†ç¡®çš„ä¿¡æ¯å¼•ç”¨

- ğŸ’¡ **æ™ºèƒ½å¯¹è¯**
  - æµå¼å“åº”è¾“å‡º
  - æ€è€ƒè¿‡ç¨‹å¯è§†åŒ–
  - å¯¹è¯å†å²ä¿å­˜

- âš™ï¸ **çµæ´»é…ç½®**
  - è‡ªå®šä¹‰æœåŠ¡å™¨åœ°å€
  - å¯è°ƒèŠ‚æ€§èƒ½æ¨¡å¼
  - æ¨¡å‹å‚æ•°é…ç½®

## ğŸš€ å¿«é€Ÿå¼€å§‹

1. **å®‰è£… Ollama**
   ```bash
   # macOS
   brew install ollama

   # Linux
   curl -fsSL https://ollama.com/install.sh | sh
   ```

2. **å®‰è£…æ‰©å±•**
   - åœ¨ VS Code ä¸­æ‰“å¼€æ‰©å±•å¸‚åœº
   - æœç´¢ "VSCode Ollama"
   - ç‚¹å‡»å®‰è£…

3. **é…ç½®æ‰©å±•**
   - æ‰“å¼€å‘½ä»¤é¢æ¿ (Ctrl+Shift+P / Cmd+Shift+P)
   - è¾“å…¥ "Ollama: Settings"
   - é…ç½®æœåŠ¡å™¨åœ°å€å’Œé»˜è®¤æ¨¡å‹

4. **å¼€å§‹ä½¿ç”¨**
   - ä½¿ç”¨å‘½ä»¤ "Ollama: Open Chat" å¼€å§‹å¯¹è¯
   - åœ¨èŠå¤©ç•Œé¢é€‰æ‹©æ¨¡å‹
   - å¼€å¯/å…³é—­è”ç½‘æœç´¢
   - å‘é€æ¶ˆæ¯å¼€å§‹äº¤äº’

## ğŸ“ ä½¿ç”¨è¯´æ˜

### å‘½ä»¤åˆ—è¡¨
- `Ollama: Open Chat` - æ‰“å¼€èŠå¤©ç•Œé¢
- `Ollama: Settings` - æ‰“å¼€è®¾ç½®é¡µé¢
- `Ollama: Test Connection` - æµ‹è¯•æœåŠ¡å™¨è¿æ¥

### å¿«æ·é”®
- `Shift + Enter` - åœ¨èŠå¤©è¾“å…¥æ¡†ä¸­æ¢è¡Œ
- `Enter` - å‘é€æ¶ˆæ¯
- `Esc` - å…³é—­å½“å‰é¢æ¿

### é…ç½®é¡¹

## Features

- Configure and use Ollama models directly from VSCode
- Customize model settings including max tokens and performance mode
- Test connection to Ollama server
- View current configuration

## Requirements

- VSCode 1.60.0 or higher
- Ollama installed and running locally

## Extension Settings

This extension contributes the following settings:

* `vscode-ollama.baseUrl`: Ollama server URL
* `vscode-ollama.model`: Selected Ollama model
* `vscode-ollama.maxTokens`: Maximum tokens for context and response
* `vscode-ollama.keepAlive`: Model keep-alive duration
* `vscode-ollama.performanceMode`: Performance mode selection

## Commands

* `Ollama: Open Settings`: Display current Ollama settings
* `Ollama: Test Server Connection`: Test connection to Ollama server
* `Ollama: Refresh Models`: Refresh available models list
* `Ollama: Open Chat`: Open chat interface to interact with Ollama

## Release Notes

### 0.0.1

Initial release of VSCode Ollama
